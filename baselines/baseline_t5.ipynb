{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## For running the T5 vanilla baseline\n",
    "1. Setup datafiles for running t5 (i.e. produce json files)\n",
    "1. Run the seq2seq model to produce outputs, saving in a directory that matches k_t5_outputs below\n",
    "    - Train model (produces saved checkpoints)\n",
    "    - Eval top performing model (load from top checkpoint, produces json outputs)\n",
    "\n",
    "1. run the eval code here using the json output from model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../decrypt')\n",
    "from decrypt.scrape_parse import (\n",
    "    load_guardian_splits,\n",
    "    load_guardian_splits_disjoint,\n",
    "    load_guardian_splits_disjoint_hash\n",
    ")\n",
    "\n",
    "import os\n",
    "import config\n",
    "from decrypt.common import validation_tools as vt\n",
    "from decrypt.common.util_data import clue_list_tuple_to_train_split_json\n",
    "import logging\n",
    "logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "k_json_folder = config.DataDirs.Guardian.json_folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Produce datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decrypt.scrape_parse.guardian_load:loading from /Users/jsrozner/jsrozner/cryptic/decrypt/data/puzzles\n",
      "INFO:decrypt.scrape_parse.guardian_load:Using file glob at /Users/jsrozner/jsrozner/cryptic/decrypt/data/puzzles/cryptic*.json\n",
      "INFO:decrypt.scrape_parse.guardian_load:Glob has size 5518\n",
      "INFO:decrypt.scrape_parse.guardian_load:Glob size matches the expected one from Decrypting paper\n",
      "100%|██████████| 5518/5518 [00:12<00:00, 448.52it/s]\n",
      " 70%|███████   | 100848/143991 [00:01<00:00, 76506.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"length punct: '\", 1),\n",
      " ('invalid: clue group', 7687),\n",
      " ('invalid: invalid start char (most are continuation clues)', 607),\n",
      " ('invalid: number in clue (commonly references another clue)', 7066),\n",
      " ('invalid: regexp', 75),\n",
      " ('invalid: soln length does not match specified lens (multi box soln)', 56),\n",
      " ('invalid: unrecognized char in clue (e.g. html)', 85),\n",
      " ('invalid: zero-len clue text after regexp', 15),\n",
      " ('length punct: ,', 24644),\n",
      " ('length punct: -', 4148),\n",
      " ('length punct: .', 8),\n",
      " ('length punct: /', 1),\n",
      " ('stat: parsed_puzzle', 5518),\n",
      " ('stat: total_clues', 143991),\n",
      " (1, 119956),\n",
      " (2, 20272),\n",
      " (3, 2957),\n",
      " (4, 686),\n",
      " (5, 112),\n",
      " (6, 8)]\n",
      "Total clues: len(puzz_list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143991/143991 [00:01<00:00, 130467.53it/s]\n",
      "100%|██████████| 55783/55783 [00:02<00:00, 24200.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 1611 exact dupes\n",
      "142380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decrypt.scrape_parse.guardian_load:Counter({1: 118540, 2: 20105, 3: 2929, 4: 686, 5: 112, 6: 8})\n",
      "INFO:decrypt.scrape_parse.guardian_load:Clue list length matches Decrypting paper expected length\n",
      "INFO:decrypt.scrape_parse.guardian_load:Got splits of lenghts [75847, 32628, 33905]\n",
      "INFO:decrypt.scrape_parse.guardian_load:First three clues of train set:\n",
      "\t[GuardianClue(clue='Sailor boy in his hammock', lengths=[4], soln='abed', soln_with_spaces='abed', idx=34809, dataset=PosixPath('/Users/jsrozner/jsrozner/cryptic/decrypt/data/puzzles'), across_or_down='across', pos=(0, 2), unique_clue_id='cryptic_23048_10-across', type='cryptic', number=23048, id='crosswords/cryptic/23048', creator='Rufus', orig_lengths='4', lengths_punctuation=set()), GuardianClue(clue='With a degree, I leave this subject', lengths=[5], soln='maths', soln_with_spaces='maths', idx=412, dataset=PosixPath('/Users/jsrozner/jsrozner/cryptic/decrypt/data/puzzles'), across_or_down='across', pos=(0, 13), unique_clue_id='cryptic_27305_24-across', type='cryptic', number=27305, id='crosswords/cryptic/27305', creator='Rufus', orig_lengths='5', lengths_punctuation=set()), GuardianClue(clue='Burrow to cure limb and make sure one gets up', lengths=[3, 3, 5], soln='setthealarm', soln_with_spaces='set the alarm', idx=116809, dataset=PosixPath('/Users/jsrozner/jsrozner/cryptic/decrypt/data/puzzles'), across_or_down='across', pos=(4, 6), unique_clue_id='cryptic_24812_14-across', type='cryptic', number=24812, id='crosswords/cryptic/24812', creator='Araucaria', orig_lengths='3,3,5', lengths_punctuation={','})]\n",
      "100%|██████████| 75847/75847 [00:00<00:00, 206955.23it/s]\n",
      "100%|██████████| 32628/32628 [00:00<00:00, 245525.96it/s]\n",
      "100%|██████████| 33905/33905 [00:00<00:00, 244112.32it/s]\n",
      "INFO:decrypt.common.util_data:Source target mapping:\n",
      "\tSailor boy in his hammock (4) => abed\n",
      "\n",
      "INFO:decrypt.common.util_data:Finished writing all files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 34809, 'input': 'Sailor boy in his hammock (4)', 'target': 'abed'}\n",
      "{'idx': 412,\n",
      " 'input': 'With a degree, I leave this subject (5)',\n",
      " 'target': 'maths'}\n",
      "{'idx': 116809,\n",
      " 'input': 'Burrow to cure limb and make sure one gets up (3,3,5)',\n",
      " 'target': 'set the alarm'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(split_type: str, overwrite=False):\n",
    "    assert split_type in ['naive_random', 'naive_disjoint', 'word_init_disjoint']\n",
    "    if split_type == 'naive_random':\n",
    "        load_fn = load_guardian_splits\n",
    "        tgt_dir = config.DataDirs.DataExport.guardian_naive_random_split\n",
    "    elif split_type == 'naive_disjoint':\n",
    "        load_fn = load_guardian_splits_disjoint\n",
    "        tgt_dir = config.DataDirs.DataExport.guardian_naive_disjoint_split\n",
    "    else:\n",
    "        load_fn = load_guardian_splits_disjoint_hash\n",
    "        tgt_dir = config.DataDirs.DataExport.guardian_word_init_disjoint_split\n",
    "\n",
    "    _, _, (train, val, test) = load_fn(k_json_folder)\n",
    "\n",
    "    os.makedirs(tgt_dir, exist_ok=True)\n",
    "    # write the output as json\n",
    "    try:\n",
    "        clue_list_tuple_to_train_split_json((train, val, test),\n",
    "                                            comment=f'Guardian data. Split: {split_type}',\n",
    "                                            export_dir=tgt_dir,\n",
    "                                            overwrite=overwrite)\n",
    "    except FileExistsError:\n",
    "        logging.warning(f'You have already generated the {split_type} dataset.\\n'\n",
    "                        f'It is located at {tgt_dir}\\n'\n",
    "                        f'To regenerate, pass overwrite=True or delete it\\n')\n",
    "\n",
    "\n",
    "make_dataset('naive_random')\n",
    "make_dataset('word_init_disjoint')\n",
    "# you can also make_dataset('naive_disjoint')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Running (training) the model\n",
    "1. Setup environment\n",
    "    1. You should setup wandb for logging (that's where metrics will show up).\n",
    "    If you try to run, the wandb will tell you what you need to do to initialize\n",
    "1. Train the model\n",
    "    1. from directory seq2seq, run the commands in the box below\n",
    "    1. Will produce model checkpoints\n",
    "\n",
    "# TODO\n",
    "todo: environment setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Choose place for your wandb dir, e.g., `'./wandb' `\n",
    "- Note that the default arguments are given in args_cryptic. See `--default_train` and `--default_val`\n",
    "- Note that it looks like epochs start at 11, so that we have space for 10 \"warmup\" epochs for curricular training - this is so that plots in wandb will line up\n",
    "\n",
    "Baseline naive\n",
    "```python\n",
    "train_clues.py --default_train=base --name=baseline_naive --project=baseline --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/naive_random'\n",
    "```\n",
    "Baseline disjoint (word initial disjoint)\n",
    "```python\n",
    "train_clues.py --default_train=base --name=baseline_disj --project=baseline --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/word_initial_disjoint'\n",
    "```\n",
    "\n",
    "Baseline (naive split), without lengths\n",
    "```python\n",
    "train_clues.py --default_train=base --name=baseline_naive_nolens --project=baseline --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/word_initial_disjoint' --special=no_lens\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Evaluating the model\n",
    "For training we generate only 5 beams. For eval we are going to generate 100.\n",
    "1. Select the best model based on num_match_top_sampled\n",
    "2. Run eval using that model\n",
    "3. This will produce a file in a new wandb directory that looks like `epoch_11.pth.tar.preds.json` (i.e a single epoch)\n",
    "\n",
    "For example,\n",
    "\n",
    "Baseline naive, if epoch 10 is best (you'll need to set the run_name)\n",
    "This runs the eval set\n",
    "```python\n",
    "train_clues.py --default_val=base --name=baseline_naive_val --project=baseline --data_dir='../data/clue_json/guardian/naive_random' --ckpt_path='./wandb/run_name/files/epoch_10.pth.tar\n",
    "```\n",
    "\n",
    "To test the test set, add `--test`\n",
    "```python\n",
    "train_clues.py --default_val=base --name=baseline_naive_val --project=baseline --data_dir='../data/clue_json/guardian/naive_random' --ckpt_path='./wandb/run_name/files/epoch_10.pth.tar --test\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we evaluate the json that was produced\n",
    "1. Change the k_t5_outputs_dir value to the location where you have saved the json files. \n",
    "    - Recommend copying all of the preds.json files into a common directory and working from that.\n",
    "    - Alternatively you could modify the code below and pass in a full path name to each of the json outputs (using the wandb directory path)\n",
    "1. For each t5 model eval that you ran, run `load_and_run()` to get metrics for those outputs\n",
    "1. The resulting outputs are the values we report in the tables. See `decrypt/common/validation_tools.ModelEval` for more details about the numbers that are produced. Percentages are prefixed by agg_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28476\n",
      "[('agg_filter_len_pre_truncate', 44.504495013344574),\n",
      " ('agg_filtered_few', 0.007093692934400899),\n",
      " ('agg_generate_few', 0.0),\n",
      " ('agg_generate_none', 0.0),\n",
      " ('agg_in_filtered', 0.4591234723978087),\n",
      " ('agg_in_sample', 0.2807978648686613),\n",
      " ('agg_sample_len', 10.0),\n",
      " ('agg_sample_len_correct', 0.48454136816968674),\n",
      " ('agg_sample_len_pre_truncate', 100.0),\n",
      " ('agg_sample_wordct_correct', 0.9789858126141312),\n",
      " ('agg_top_10_after_filter', 0.3385658098047479),\n",
      " ('agg_top_match', 0.1630495856159573),\n",
      " ('agg_top_match_len_correct', 0.9998946481247366),\n",
      " ('agg_top_match_none', 0.00010535187526337969),\n",
      " ('agg_top_match_wordct_correct', 0.9942407641522686),\n",
      " ('agg_top_sample_result_len_correct', 0.560858266610479),\n",
      " ('agg_top_sample_result_wordct_correct', 0.9846186262115466),\n",
      " ('filter_len_pre_truncate', 1267310),\n",
      " ('filtered_few', 202),\n",
      " ('generate_few', 0),\n",
      " ('generate_none', 0),\n",
      " ('in_filtered', 13074),\n",
      " ('in_sample', 7996),\n",
      " ('sample_len', 284760),\n",
      " ('sample_len_correct', 137978),\n",
      " ('sample_len_pre_truncate', 2847600),\n",
      " ('sample_wordct_correct', 278776),\n",
      " ('top_10_after_filter', 9641),\n",
      " ('top_match', 4643),\n",
      " ('top_match_len_correct', 28473),\n",
      " ('top_match_none', 3),\n",
      " ('top_match_wordct_correct', 28312),\n",
      " ('top_sample_result_len_correct', 15971),\n",
      " ('top_sample_result_wordct_correct', 28038),\n",
      " ('total', 28476)]\n"
     ]
    }
   ],
   "source": [
    "# for example, if your output files are in\n",
    "# 'decrypt/t5_outputs/'\n",
    "# and you will run the below, e.g., if you have named the files\n",
    "# baseline_naive_e12_test.json\n",
    "# (.json will be appended for you by the load_and_run_t5 function)\n",
    "# a better name for load_and_run is load_and_eval\n",
    "\n",
    "# for example\n",
    "### primary - test\n",
    "vt.load_and_run_t5('decrypt/t5_outputs/baseline_naive_e12_test')\n",
    "vt.load_and_run_t5('decrypt/t5_outputs/baseline_naive_nolens_e15_test')     # test set\n",
    "\n",
    "## primary val\n",
    "vt.load_and_run_t5('decrypt/t5_outputs/baseline_naive_e12_val')\n",
    "vt.load_and_run_t5('decrypt/t5_outputs/baseline_naive_nolens_e15_val')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}