{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import config\n",
    "k_json_folder = config.DataDirs.Guardian.json_folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../decrypt')\n",
    "from decrypt.scrape_parse import (\n",
    "    load_guardian_splits,\n",
    "    load_guardian_splits_disjoint_hash\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from decrypt.common.puzzle_clue import GuardianClue\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from typing import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from decrypt.common import validation_tools as vt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# no need to lowercase - countvectorizer does this\n",
    "def load_data(clue_list: List[GuardianClue], add_lens=False):\n",
    "    \"\"\"\n",
    "    Take clue_list and return the X and Y data\n",
    "    \"\"\"\n",
    "    def iter_fcn(clue: GuardianClue):\n",
    "        if add_lens:\n",
    "            ret = clue.clue_with_lengths(\"|\")\n",
    "        else:\n",
    "            ret = clue.clue\n",
    "        return ret\n",
    "\n",
    "    X = [iter_fcn(c) for c in clue_list]\n",
    "    Y = [c.soln_with_spaces.lower() for c in clue_list]\n",
    "    return X, Y\n",
    "\n",
    "def knn_eval(train, val, add_lens, knn_neighbors: int, verify=False):\n",
    "    \"\"\"\n",
    "    :param add_lens: whether to add lengths to the input clues\n",
    "    :param knn_neighbors: number of neighbors to use when doing \"beam search\". None => no beam search\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    train_inputs, train_targets = load_data(train, add_lens)\n",
    "    test_inputs, test_targets = load_data(val, add_lens)\n",
    "    print(train_inputs[:2])\n",
    "\n",
    "    # set up the bag-of-words vectorizer\n",
    "    # token patter needed for the length specification\n",
    "    bow_vectorizer = CountVectorizer(token_pattern='[a-z\\d()|]+',\n",
    "                                     ngram_range=(1,1))     # further ngrams degrade performance\n",
    "    bowVect = bow_vectorizer.fit(train_inputs)\n",
    "\n",
    "    # show that everything was vectorized correctly\n",
    "    print(len(bowVect.vocabulary_))\n",
    "    if verify:\n",
    "        for w in train_inputs[0].replace(\",\",\" \").lower().split(\" \"):\n",
    "            if w == '': continue\n",
    "            print(bowVect.vocabulary_[w])\n",
    "\n",
    "    bowTrain = bowVect.transform(train_inputs)\n",
    "    bowTest = bowVect.transform(test_inputs)\n",
    "\n",
    "    # fit KNN\n",
    "    # neighbor setting here doesn't matter; can put in call to knn.kneighbors\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(bowTrain, train_targets)\n",
    "\n",
    "    # predict (runs long)\n",
    "    # get the nearest neighbors (beam search)\n",
    "    # this returns in sorted order, so commented code not needed\n",
    "    # nn_dist, nn_idx = knn.kneighbors(bowTest, n_neighbors=knn_neighbors, return_distance=True)\n",
    "    # nn_dist_and_idx = zip(nn_dist, nn_idx)\n",
    "    nn = knn.kneighbors(bowTest, n_neighbors=knn_neighbors, return_distance=False)\n",
    "\n",
    "    # get the predictions (\"greedy\")\n",
    "    pred = knn.predict(bowTest)\n",
    "    return train_targets, test_targets, nn, pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def eval_knn(val_set: List[GuardianClue],\n",
    "             train_targets,\n",
    "             test_targets,\n",
    "             nn,\n",
    "             pred):\n",
    "    model_outputs = []\n",
    "\n",
    "    # don't need to check idx set since we have a 1:1 of val_gc to test_tgt\n",
    "    # nn_list is already sorted\n",
    "    for val_gc, test_tgt, nn_list, greedy_pred in tqdm(zip(val_set, test_targets, nn, pred)):\n",
    "        assert val_gc.soln_with_spaces == test_tgt\n",
    "        neighbor_solns = [train_targets[n] for n in nn_list]\n",
    "\n",
    "        # nbr set is the list of indices of nearest neighbor\n",
    "        # we retrieve all the solns for those neighbors (y_train[i])\n",
    "        mp = vt.ModelPrediction(idx=val_gc.idx,\n",
    "                            input=val_gc.clue_with_lengths(punct=\"|\"),\n",
    "                            target=test_tgt,\n",
    "                            greedy=greedy_pred,\n",
    "                             sampled=neighbor_solns)\n",
    "\n",
    "        mp.model_eval = vt.eval(mp)\n",
    "        model_outputs.append(mp)\n",
    "\n",
    "    return model_outputs\n",
    "\n",
    "def aggregate(val, output_tuple):\n",
    "    model_out = eval_knn(val, *output_tuple)\n",
    "    vt.all_aggregate(model_out)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# eval on naive val set (with/without lens)\n",
    "def run_eval_knn(val_or_test: str, naive_or_disj: str, nn=3000):\n",
    "    assert val_or_test in [\"val\", \"test\"]\n",
    "    assert naive_or_disj in [\"naive\", \"disj\"]\n",
    "    if naive_or_disj == \"naive\":\n",
    "        load_fn = load_guardian_splits\n",
    "    else:\n",
    "        load_fn = load_guardian_splits_disjoint_hash\n",
    "    _, _, (train_local, val, test) = load_fn(k_json_folder)\n",
    "    if val_or_test == \"val\":\n",
    "        val_local = val\n",
    "    else:\n",
    "        val_local = test\n",
    "\n",
    "    knn_tuple_random_val_nolens = knn_eval(train_local, val_local, add_lens=False, knn_neighbors=nn)\n",
    "    aggregate(val_local, knn_tuple_random_val_nolens)\n",
    "\n",
    "    knn_tuple_random_val_lens = knn_eval(train_local, val_local, add_lens=True, knn_neighbors=nn)\n",
    "    aggregate(val_local, knn_tuple_random_val_lens)\n",
    "\n",
    "    return knn_tuple_random_val_nolens, knn_tuple_random_val_lens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decrypt.scrape_parse.guardian_load:loading from ../puzzles/\n",
      "INFO:decrypt.scrape_parse.guardian_load:Using file glob at ../puzzles/cryptic*.json\n",
      "INFO:decrypt.scrape_parse.guardian_load:Glob has size 5518\n",
      "INFO:decrypt.scrape_parse.guardian_load:Glob size matches the expected one from Decrypting paper\n",
      "100%|██████████| 5518/5518 [00:12<00:00, 454.75it/s]\n",
      "  5%|▌         | 7311/143991 [00:00<00:05, 24179.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"length punct: '\", 1),\n",
      " ('invalid: clue group', 7687),\n",
      " ('invalid: invalid start char (most are continuation clues)', 607),\n",
      " ('invalid: number in clue (commonly references another clue)', 7066),\n",
      " ('invalid: regexp', 75),\n",
      " ('invalid: soln length does not match specified lens (multi box soln)', 56),\n",
      " ('invalid: unrecognized char in clue (e.g. html)', 85),\n",
      " ('invalid: zero-len clue text after regexp', 15),\n",
      " ('length punct: ,', 24644),\n",
      " ('length punct: -', 4148),\n",
      " ('length punct: .', 8),\n",
      " ('length punct: /', 1),\n",
      " ('stat: parsed_puzzle', 5518),\n",
      " ('stat: total_clues', 143991),\n",
      " (1, 119956),\n",
      " (2, 20272),\n",
      " (3, 2957),\n",
      " (4, 686),\n",
      " (5, 112),\n",
      " (6, 8)]\n",
      "Total clues: len(puzz_list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143991/143991 [00:00<00:00, 276338.67it/s]\n",
      "100%|██████████| 55783/55783 [00:02<00:00, 21140.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 1611 exact dupes\n",
      "142380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decrypt.scrape_parse.guardian_load:Counter({1: 118540, 2: 20105, 3: 2929, 4: 686, 5: 112, 6: 8})\n",
      "INFO:decrypt.scrape_parse.guardian_load:Clue list length matches Decrypting paper expected length\n",
      "INFO:decrypt.scrape_parse.guardian_load:Got splits of lenghts [85428, 28476, 28476]\n",
      "INFO:decrypt.scrape_parse.guardian_load:First three clues of train set:\n",
      "\t[GuardianClue(clue='Suffering to grasp edge of plant', lengths=[8], soln='agrimony', soln_with_spaces='agrimony', idx=85002, dataset='../puzzles/', across_or_down='across', pos=(7, 4), unique_clue_id='cryptic_25415_11-across', type='cryptic', number=25415, id='crosswords/cryptic/25415', creator='Chifonie', orig_lengths='8', lengths_punctuation=set()), GuardianClue(clue='Honour Ben and Noel with new order', lengths=[7], soln='ennoble', soln_with_spaces='ennoble', idx=3432, dataset='../puzzles/', across_or_down='down', pos=(7, 8), unique_clue_id='cryptic_24994_18-down', type='cryptic', number=24994, id='crosswords/cryptic/24994', creator='Rufus', orig_lengths='7', lengths_punctuation=set()), GuardianClue(clue='Bit the royal we love? Cheers!', lengths=[4], soln='iota', soln_with_spaces='iota', idx=25530, dataset='../puzzles/', across_or_down='across', pos=(0, 10), unique_clue_id='cryptic_26632_21-across', type='cryptic', number=26632, id='crosswords/cryptic/26632', creator='Screw', orig_lengths='4', lengths_punctuation=set())]\n",
      "INFO:decrypt.scrape_parse.guardian_load:Verifying splits match Decrypting paper: Spot test clue 5111 has correct text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Suffering to grasp edge of plant', 'Honour Ben and Noel with new order']\n",
      "31939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28476it [00:02, 9931.91it/s] \n",
      "WARNING:root:No gsheets writer exists. No rows will be written. This warning will be printed only once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('agg_filter_len_pre_truncate', 0.16038067144261833),\n",
      " ('agg_filtered_few', 1.0),\n",
      " ('agg_generate_few', 1.0),\n",
      " ('agg_generate_none', 0.0),\n",
      " ('agg_in_filtered', 0.035995224048321395),\n",
      " ('agg_in_sample', 0.035995224048321395),\n",
      " ('agg_sample_len', 1.0),\n",
      " ('agg_sample_len_correct', 0.16038067144261833),\n",
      " ('agg_sample_len_pre_truncate', 1.0),\n",
      " ('agg_sample_wordct_correct', 0.7433277145666526),\n",
      " ('agg_top_10_after_filter', 0.035995224048321395),\n",
      " ('agg_top_match', 0.035995224048321395),\n",
      " ('agg_top_match_len_correct', 0.16038067144261833),\n",
      " ('agg_top_match_none', 0.8396193285573816),\n",
      " ('agg_top_match_wordct_correct', 0.13864306784660768),\n",
      " ('agg_top_sample_result_len_correct', 0.16038067144261833),\n",
      " ('agg_top_sample_result_wordct_correct', 0.7433277145666526),\n",
      " ('filter_len_pre_truncate', 4567),\n",
      " ('filtered_few', 28476),\n",
      " ('generate_few', 28476),\n",
      " ('generate_none', 0),\n",
      " ('in_filtered', 1025),\n",
      " ('in_sample', 1025),\n",
      " ('sample_len', 28476),\n",
      " ('sample_len_correct', 4567),\n",
      " ('sample_len_pre_truncate', 28476),\n",
      " ('sample_wordct_correct', 21167),\n",
      " ('top_10_after_filter', 1025),\n",
      " ('top_match', 1025),\n",
      " ('top_match_len_correct', 4567),\n",
      " ('top_match_none', 23909),\n",
      " ('top_match_wordct_correct', 3948),\n",
      " ('top_sample_result_len_correct', 4567),\n",
      " ('top_sample_result_wordct_correct', 21167),\n",
      " ('total', 28476)]\n",
      "['Suffering to grasp edge of plant (8)', 'Honour Ben and Noel with new order (7)']\n",
      "32466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28476it [00:02, 12824.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('agg_filter_len_pre_truncate', 0.877826941986234),\n",
      " ('agg_filtered_few', 1.0),\n",
      " ('agg_generate_few', 1.0),\n",
      " ('agg_generate_none', 0.0),\n",
      " ('agg_in_filtered', 0.058189352437140046),\n",
      " ('agg_in_sample', 0.058189352437140046),\n",
      " ('agg_sample_len', 1.0),\n",
      " ('agg_sample_len_correct', 0.877826941986234),\n",
      " ('agg_sample_len_pre_truncate', 1.0),\n",
      " ('agg_sample_wordct_correct', 0.9142786908273633),\n",
      " ('agg_top_10_after_filter', 0.058189352437140046),\n",
      " ('agg_top_match', 0.058189352437140046),\n",
      " ('agg_top_match_len_correct', 0.877826941986234),\n",
      " ('agg_top_match_none', 0.12217305801376598),\n",
      " ('agg_top_match_wordct_correct', 0.8731914594746453),\n",
      " ('agg_top_sample_result_len_correct', 0.877826941986234),\n",
      " ('agg_top_sample_result_wordct_correct', 0.9142786908273633),\n",
      " ('filter_len_pre_truncate', 24997),\n",
      " ('filtered_few', 28476),\n",
      " ('generate_few', 28476),\n",
      " ('generate_none', 0),\n",
      " ('in_filtered', 1657),\n",
      " ('in_sample', 1657),\n",
      " ('sample_len', 28476),\n",
      " ('sample_len_correct', 24997),\n",
      " ('sample_len_pre_truncate', 28476),\n",
      " ('sample_wordct_correct', 26035),\n",
      " ('top_10_after_filter', 1657),\n",
      " ('top_match', 1657),\n",
      " ('top_match_len_correct', 24997),\n",
      " ('top_match_none', 3479),\n",
      " ('top_match_wordct_correct', 24865),\n",
      " ('top_sample_result_len_correct', 24997),\n",
      " ('top_sample_result_wordct_correct', 26035),\n",
      " ('total', 28476)]\n"
     ]
    }
   ],
   "source": [
    "# knn_tuple_random_val_nolens, knn_tuple_random_val_lens = eval_naive_val()\n",
    "# run with nn=3000 to replicate research\n",
    "knn_tuple_random_val_nolens, knn_tuple_random_val_lens = run_eval_knn(val_or_test=\"val\",\n",
    "                                                                      naive_or_disj=\"naive\",\n",
    "                                                                      nn=1)\n",
    "# %store knn_tuple_random_val_nolens\n",
    "# %store knn_tuple_random_val_lens\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Suffering to grasp edge of plant (8)', 'Honour Ben and Noel with new order (7)']\n",
      "32466\n",
      "\n",
      "0\n",
      "very\n",
      "31148\n",
      "1\n",
      "sad\n",
      "24960\n",
      "2\n",
      "to\n",
      "29352\n",
      "3\n",
      "find\n",
      "11477\n",
      "4\n",
      "out\n",
      "20378\n",
      "5\n",
      "whats\n",
      "6\n",
      "popular\n",
      "21973\n",
      "7\n",
      "on\n",
      "20096\n",
      "8\n",
      "twitter\n",
      "30162\n",
      "9\n",
      "(5|7)\n",
      "447\n",
      "[31148, 24960, 29352, 11477, 20378, 21973, 20096, 30162, 447]\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Supplementary to verify KNN works the way we expect\n",
    "###\n",
    "\n",
    "## verify how KNN does tokenization\n",
    "train_inputs, train_targets = load_data(train, True)\n",
    "print(train_inputs[:2])\n",
    "\n",
    "# set up the bag-of-words vectorizer\n",
    "# token patter needed for the length specification\n",
    "# punctuation not included in token pattern (e.g. , or ') will be split and treated as space\n",
    "# see below experiment\n",
    "bow_vectorizer = CountVectorizer(token_pattern='[a-z\\d()|]+',\n",
    "                                 ngram_range=(1,1))     # further ngrams degrade performance\n",
    "bowVect = bow_vectorizer.fit(train_inputs)\n",
    "\n",
    "# show that everything was vectorized correctly\n",
    "print(len(bowVect.vocabulary_))\n",
    "print()\n",
    "# for w in train_inputs[0].replace(\",\",\" \").lower().split(\" \"):\n",
    "# need to replace any punct that occurs\n",
    "all = []\n",
    "for idx, w in enumerate(train_inputs[12].replace(\"'\", \"\").lower().split(\" \")):\n",
    "    print(w)\n",
    "    try:\n",
    "        val = bowVect.vocabulary_[w]\n",
    "        print(val)\n",
    "        all.append(val)\n",
    "    except:\n",
    "        pass\n",
    "print(sorted(all))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[447, 11477, 20096, 20378, 21973, 24960, 29352, 30162, 31148]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very sad to find out what's popular on Twitter (5|7)\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs[12])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 447)\t1\n",
      "  (0, 11477)\t1\n",
      "  (0, 20096)\t1\n",
      "  (0, 20378)\t1\n",
      "  (0, 21973)\t1\n",
      "  (0, 24933)\t1\n",
      "  (0, 24960)\t1\n",
      "  (0, 29352)\t1\n",
      "  (0, 30162)\t1\n",
      "  (0, 31148)\t1\n",
      "  (0, 31779)\t1\n"
     ]
    }
   ],
   "source": [
    "matrix = bow_vectorizer.transform([train_inputs[12]])\n",
    "print(matrix)\n",
    "for i,j in matrix:\n",
    "    print(bowVect.vocabulary_[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[array(['(5|7)', 'find', 'on', 'out', 'popular', 's', 'sad', 'to',\n        'twitter', 'very', 'what'], dtype='<U20')]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectorizer.inverse_transform(matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, c in enumerate(train):\n",
    "    if len(c.lengths) > 1:\n",
    "        print(c.idx)\n",
    "        print(i)\n",
    "        break\n",
    "print(train_inputs[12])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}