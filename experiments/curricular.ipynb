{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting up for curricular experiment\n",
    "\n",
    "This assumes you have already followed the instructions in `baselines/baseline_t5`, which will set up the baseline clue files for model input\n",
    "\n",
    "### Datasets\n",
    "1. Download and unzip the xd cw crossword set from http://xd.saul.pw/xd-clues.zip.\n",
    "    - Save it as './data/original/xd/clues.tsv'\n",
    "2. Preprocess the dataset using this notebook\n",
    "3. The dataset will be saved to k_acw_export_dir (as a single train.json file)\n",
    "4. We will also produce the anagram dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No gsheets writer is configured\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from decrypt.scrape_parse.acw_load import get_clean_xd_clues\n",
    "from decrypt import config\n",
    "from decrypt.common.util_data import clue_list_tuple_to_train_split_json\n",
    "from decrypt.common import validation_tools as vt\n",
    "\n",
    "k_xd_orig_tsv = config.DataDirs.OriginalData.k_xd_cw        # ./data/original/xd/clues.tsv\n",
    "k_acw_export_dir = config.DataDirs.DataExport.xd_cw_json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading xd (ACW) set from /Users/jsrozner/MOUNT/scdt/decrypt/data/original/xd/clues.tsv\n",
      "INFO:root:Reading file into dict: /Users/jsrozner/MOUNT/scdt/decrypt/data/generated/twl_dict.txt\n",
      "8719it [00:00, 87173.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized a spellchecker\n",
      "This will fail if you have not downloaded or generated twl_dict.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "178691it [00:00, 262449.77it/s]\n",
      "INFO:root:Done reading file: /Users/jsrozner/MOUNT/scdt/decrypt/data/generated/twl_dict.txt\n",
      "INFO:root:Reading file into dict: /Users/jsrozner/MOUNT/scdt/decrypt/data/original/us/US.dic\n",
      "118619it [00:00, 224014.82it/s]\n",
      "INFO:root:Done reading file: /Users/jsrozner/MOUNT/scdt/decrypt/data/original/us/US.dic\n",
      "INFO:root:Done setting up spellchecker\n",
      "6338031it [13:17, 7949.77it/s] \n",
      "INFO:root:Counter({'not_in_dict': 1315223, 'removed_trailing_period': 501854, 'fillin': 381519, 'removed_likely_abbrev': 100730, 'question word': 92650, 'empty': 75929, 'ref': 30220})\n",
      "INFO:root:Filtered to 4341760 clues\n",
      "  1%|          | 50438/4341760 [00:00<00:08, 504345.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'not_in_dict': 1315223, 'removed_trailing_period': 501854, 'fillin': 381519, 'removed_likely_abbrev': 100730, 'question word': 92650, 'empty': 75929, 'ref': 30220})\n",
      "DEL called for spellchecker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4341760/4341760 [00:15<00:00, 280043.52it/s]\n",
      "100%|██████████| 86633/86633 [01:54<00:00, 755.28it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 2545682 exact dupes\n",
      "1796078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Counter({1: 1796078})\n",
      "100%|██████████| 1796078/1796078 [00:20<00:00, 85671.75it/s] \n",
      "INFO:decrypt.common.util_data:Source target mapping:\n",
      "\tLitigator's group (3) => aba\n",
      "\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "Cannot write since file_name already exists and overwrite not specified",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileExistsError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-6b576a0f4909>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m                                         \u001B[0mremove_if_not_in_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                                         do_filter_dupes=True)\n\u001B[0;32m----> 5\u001B[0;31m clue_list_tuple_to_train_split_json((all_clues,),\n\u001B[0m\u001B[1;32m      6\u001B[0m                                     \u001B[0mcomment\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'ACW set; xd cw set, all'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m                                     \u001B[0mexport_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mk_acw_export_dir\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/MOUNT/scdt/decrypt/decrypt/common/util_data.py\u001B[0m in \u001B[0;36mclue_list_tuple_to_train_split_json\u001B[0;34m(clue_list_tuple, comment, export_dir, mod_fn, overwrite)\u001B[0m\n\u001B[1;32m     92\u001B[0m              f'\\t{out_ex[\"input\"]} => {out_ex[\"target\"]}\\n')\n\u001B[1;32m     93\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 94\u001B[0;31m     \u001B[0mwrite_json_tuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjson_output_tuple\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcomment\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexport_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moverwrite\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverwrite\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmod_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmod_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     95\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[0;31m###\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/MOUNT/scdt/decrypt/decrypt/common/util_data.py\u001B[0m in \u001B[0;36mwrite_json_tuple\u001B[0;34m(json_tuple, comment, export_dir, overwrite, mod_fn)\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mjson_out\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjson_tuple\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mk_data_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m         \u001B[0mtgt_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexport_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\".json\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m         \u001B[0mwrite_json_to_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjson_out\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtgt_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0;31m# write a description\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/MOUNT/scdt/decrypt/decrypt/common/util_data.py\u001B[0m in \u001B[0;36mwrite_json_to_file\u001B[0;34m(json_dict, path)\u001B[0m\n\u001B[1;32m     41\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrite_json_to_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjson_dict\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0moverwrite\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 43\u001B[0;31m             \u001B[0m_check_overwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     44\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'w'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mfh\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m             \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjson_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfh\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/MOUNT/scdt/decrypt/decrypt/common/util_data.py\u001B[0m in \u001B[0;36m_check_overwrite\u001B[0;34m(filename)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_check_overwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mFileExistsError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Cannot write since file_name already exists and overwrite not specified\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m \u001B[0;31m#######\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;31m# Dataset generation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileExistsError\u001B[0m: Cannot write since file_name already exists and overwrite not specified"
     ]
    }
   ],
   "source": [
    "# defaults to strip periods, remove questions, remove abbrevs, remove fillin\n",
    "stc_map, all_clues = get_clean_xd_clues(k_xd_orig_tsv,\n",
    "                                        remove_if_not_in_dict=False,\n",
    "                                        do_filter_dupes=True)\n",
    "clue_list_tuple_to_train_split_json((all_clues,),\n",
    "                                    comment='ACW set; xd cw set, all',\n",
    "                                    export_dir=k_acw_export_dir,\n",
    "                                    overwrite=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Overwriting database at /Users/jsrozner/MOUNT/scdt/decrypt/data/generated/anag_db\n",
      "INFO:root:Adding to db /Users/jsrozner/MOUNT/scdt/decrypt/data/generated/anag_db with updateflag overwrite\n",
      "118619it [00:29, 4053.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 118609})\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# produce anagram datasets\n",
    "# roughly 3 minutes to complete\n",
    "from decrypt.common import anagrammer\n",
    "anagrammer.gen_db_with_both_inputs(update_flag=\"overwrite\")\n",
    "\n",
    "from decrypt.common.util_data import (\n",
    "    get_anags,\n",
    "    write_json_tuple\n",
    ")\n",
    "import json\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def make_anag_sets_json():\n",
    "    all_anags = get_anags(max_num_words=-1)\n",
    "    json_list = []\n",
    "    for idx, a_list in enumerate(all_anags):\n",
    "        json_list.append(dict(idx=idx,\n",
    "                              anag_list=a_list))\n",
    "    print(json_list[0])\n",
    "\n",
    "    # normally would be (idx, input, tgt)\n",
    "    output_tuple = [json_list,]\n",
    "\n",
    "    os.makedirs(config.DataDirs.DataExport.anag_dir)\n",
    "    write_json_tuple(output_tuple,\n",
    "                     comment=\"List of all anagram groupings\",\n",
    "                     export_dir=config.DataDirs.DataExport.anag_dir,\n",
    "                     overwrite=False)\n",
    "\n",
    "def make_anag_indic_list_json():\n",
    "    # make the indicator list\n",
    "    with open(config.DataDirs.OriginalData.k_deits_anagram_list, 'r') as f:\n",
    "        all_anag_indicators = f.readlines()\n",
    "        print(len(all_anag_indicators))\n",
    "\n",
    "    final_indic_list = []\n",
    "    for a in all_anag_indicators:\n",
    "        final_indic_list.append(a.replace('_', \" \").strip())\n",
    "    with open(config.DataDirs.DataExport.anag_indics, 'w') as f:\n",
    "        json.dump(final_indic_list,f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing (non-singleton) Anagrammer from /Users/jsrozner/MOUNT/scdt/decrypt/data/generated/anag_db\n",
      "INFO:root:DONE: Initialized Anagrammer from /Users/jsrozner/MOUNT/scdt/decrypt/data/generated/anag_db\n",
      "100%|██████████| 187438/187438 [00:04<00:00, 41704.05it/s]\n",
      "INFO:root:Total anagramable: 13535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13535\n",
      "13535\n",
      "32305\n",
      "['titan', 'taint', 'tat in']\n",
      "{'idx': 0, 'anag_list': ['titan', 'taint', 'tat in']}\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/jsrozner/MOUNT/scdt/decrypt/data/clue_json/curricular/anagram'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileExistsError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-534806101917>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmake_anag_sets_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-8-9e64d72f398c>\u001B[0m in \u001B[0;36mmake_anag_sets_json\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0moutput_tuple\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mjson_list\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m     \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmakedirs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataDirs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataExport\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0manag_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m     write_json_tuple(output_tuple,\n\u001B[1;32m     14\u001B[0m                      \u001B[0mcomment\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"List of all anagram groupings\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/cryptic-new/lib/python3.8/os.py\u001B[0m in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    221\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 223\u001B[0;31m         \u001B[0mmkdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    224\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m         \u001B[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileExistsError\u001B[0m: [Errno 17] File exists: '/Users/jsrozner/MOUNT/scdt/decrypt/data/clue_json/curricular/anagram'"
     ]
    }
   ],
   "source": [
    "make_anag_sets_json()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_anag_indic_list_json()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Curricular training\n",
    "1. At this point you should have a files at\n",
    " - `./data/clue_json/curricular/ACW/train.json`\n",
    " - `./data/clue_json/curricular/anagram/[train.json, anag_indics.json]`\n",
    "\n",
    "2. Running curricular training is the same as running main t5 vanilla train, except that we pass an extra multitask flag, which specifies the curriculum to use. See `seq2seq/multitask_config`. You should pass one of the names from  `multi_config` dict in that file\n",
    "\n",
    "For example, to train the naive split with the top performing curricular approach (i.e. the result in table 3 that is ACW + ACW-descramble)\n",
    "```python\n",
    "python train_clues.py --default_train=base --name=naive_top_curricular --project=curricular --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/naive_random' --multitask=ACW__ACW_descramble\n",
    "```\n",
    "\n",
    "Note that the modifications on the dataset are done at the\n",
    "\n",
    "3. To produce Table 3 of the results\n",
    "    -  we don't need to do a model_eval run since the outputted predictions have 5 generations\n",
    "       (which is all we report for that table (for faster experimental iteration).\n",
    "    - we need to run `load_and_run_t5` on all outputs (column 1) and on the anagram subset (column 2)\n",
    "      See below for how we do this.\n",
    "\n",
    "4. For our top result in Table 2 (main resuls) we\n",
    "    1. scale up the curricular period (to 4 total epochs)\n",
    "```python\n",
    "python train_clues.py --default_train=base --name=naive_top_curricular --project=curricular --wandb_dir='./wandb' --data_dir='../data/clue_json/guardian/naive_random' --multitask=final_top_result_scaled_up\n",
    "```\n",
    "    2. eval with full 100 generations, as before:\n",
    "e.g., if epoch 10 is best (you'll need to set the run_name)\n",
    "This runs the eval set (change the run_name)\n",
    "```python\n",
    "python train_clues.py --default_val=base --name=curricular_naive_top --project=curricular --data_dir='../data/clue_json/guardian/naive_random' --ckpt_path='./wandb/run_name/files/epoch_10.pth.tar\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No gsheets writer is configured\n",
      "INFO:decrypt.scrape_parse.guardian_load:loading from /Users/jsrozner/MOUNT/scdt/cryptic_nlp/decrypt_root/data/puzzles\n",
      "INFO:decrypt.scrape_parse.guardian_load:Using file glob at /Users/jsrozner/MOUNT/scdt/cryptic_nlp/decrypt_root/data/puzzles/cryptic*.json\n",
      "INFO:decrypt.scrape_parse.guardian_load:Glob has size 5518\n",
      "INFO:decrypt.scrape_parse.guardian_load:Glob size matches the expected one from Decrypting paper\n",
      "100%|██████████| 5518/5518 [01:23<00:00, 66.35it/s]\n",
      "  5%|▍         | 6769/143991 [00:00<00:06, 19804.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"length punct: '\", 1),\n",
      " ('invalid: clue group', 7687),\n",
      " ('invalid: invalid start char (most are continuation clues)', 607),\n",
      " ('invalid: number in clue (commonly references another clue)', 7066),\n",
      " ('invalid: regexp', 75),\n",
      " ('invalid: soln length does not match specified lens (multi box soln)', 56),\n",
      " ('invalid: unrecognized char in clue (e.g. html)', 85),\n",
      " ('invalid: zero-len clue text after regexp', 15),\n",
      " ('length punct: ,', 24644),\n",
      " ('length punct: -', 4148),\n",
      " ('length punct: .', 8),\n",
      " ('length punct: /', 1),\n",
      " ('stat: parsed_puzzle', 5518),\n",
      " ('stat: total_clues', 143991),\n",
      " (1, 119956),\n",
      " (2, 20272),\n",
      " (3, 2957),\n",
      " (4, 686),\n",
      " (5, 112),\n",
      " (6, 8)]\n",
      "Total clues: len(puzz_list)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143991/143991 [00:00<00:00, 228548.02it/s]\n",
      "100%|██████████| 55783/55783 [00:03<00:00, 15482.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 1611 exact dupes\n",
      "142380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:decrypt.scrape_parse.guardian_load:Counter({1: 118540, 2: 20105, 3: 2929, 4: 686, 5: 112, 6: 8})\n",
      "INFO:decrypt.scrape_parse.guardian_load:Clue list length matches Decrypting paper expected length\n",
      "INFO:decrypt.scrape_parse.guardian_load:Got splits of lenghts [85428, 28476, 28476]\n",
      "INFO:decrypt.scrape_parse.guardian_load:First three clues of train set:\n",
      "\t[GuardianClue(clue='Suffering to grasp edge of plant', lengths=[8], soln='agrimony', soln_with_spaces='agrimony', idx=85002, dataset=PosixPath('/Users/jsrozner/MOUNT/scdt/cryptic_nlp/decrypt_root/data/puzzles'), across_or_down='across', pos=(7, 4), unique_clue_id='cryptic_25415_11-across', type='cryptic', number=25415, id='crosswords/cryptic/25415', creator='Chifonie', orig_lengths='8', lengths_punctuation=set()), GuardianClue(clue='Honour Ben and Noel with new order', lengths=[7], soln='ennoble', soln_with_spaces='ennoble', idx=3432, dataset=PosixPath('/Users/jsrozner/MOUNT/scdt/cryptic_nlp/decrypt_root/data/puzzles'), across_or_down='down', pos=(7, 8), unique_clue_id='cryptic_24994_18-down', type='cryptic', number=24994, id='crosswords/cryptic/24994', creator='Rufus', orig_lengths='7', lengths_punctuation=set()), GuardianClue(clue='Bit the royal we love? Cheers!', lengths=[4], soln='iota', soln_with_spaces='iota', idx=25530, dataset=PosixPath('/Users/jsrozner/MOUNT/scdt/cryptic_nlp/decrypt_root/data/puzzles'), across_or_down='across', pos=(0, 10), unique_clue_id='cryptic_26632_21-across', type='cryptic', number=26632, id='crosswords/cryptic/26632', creator='Screw', orig_lengths='4', lengths_punctuation=set())]\n",
      "INFO:decrypt.scrape_parse.guardian_load:Verifying splits match Decrypting paper: Spot test clue 5111 has correct text\n",
      "100%|██████████| 142380/142380 [00:08<00:00, 17357.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from decrypt.common.label_anagrams import make_label_set\n",
    "\n",
    "labels = make_label_set()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28476\n",
      "[('agg_filter_len_pre_truncate', 4.572166034555415),\n",
      " ('agg_filtered_few', 1.0),\n",
      " ('agg_generate_few', 1.0),\n",
      " ('agg_generate_none', 0.0),\n",
      " ('agg_in_filtered', 0.3338952100014047),\n",
      " ('agg_in_sample', 0.3338952100014047),\n",
      " ('agg_sample_len', 5.0),\n",
      " ('agg_sample_len_correct', 0.919244275881444),\n",
      " ('agg_sample_len_pre_truncate', 5.0),\n",
      " ('agg_sample_wordct_correct', 0.9760640539401602),\n",
      " ('agg_top_10_after_filter', 0.3338952100014047),\n",
      " ('agg_top_match', 0.20213513133867117),\n",
      " ('agg_top_match_len_correct', 0.9922039612305099),\n",
      " ('agg_top_match_none', 0.007796038769490097),\n",
      " ('agg_top_match_wordct_correct', 0.9868310155920775),\n",
      " ('agg_top_sample_result_len_correct', 0.9403708386009271),\n",
      " ('agg_top_sample_result_wordct_correct', 0.9830734653743504),\n",
      " ('filter_len_pre_truncate', 130197),\n",
      " ('filtered_few', 28476),\n",
      " ('generate_few', 28476),\n",
      " ('generate_none', 0),\n",
      " ('in_filtered', 9508),\n",
      " ('in_sample', 9508),\n",
      " ('sample_len', 142380),\n",
      " ('sample_len_correct', 130882),\n",
      " ('sample_len_pre_truncate', 142380),\n",
      " ('sample_wordct_correct', 138972),\n",
      " ('top_10_after_filter', 9508),\n",
      " ('top_match', 5756),\n",
      " ('top_match_len_correct', 28254),\n",
      " ('top_match_none', 222),\n",
      " ('top_match_wordct_correct', 28101),\n",
      " ('top_sample_result_len_correct', 26778),\n",
      " ('top_sample_result_wordct_correct', 27994),\n",
      " ('total', 28476)]\n"
     ]
    }
   ],
   "source": [
    "# note that this should be run directly on the top model output from curricular training\n",
    "# otherwise (eg. if 100 beams were used), the top 5 output\n",
    "# sequences would be expected to change\n",
    "# remember not to append .json\n",
    "\n",
    "# eval on the full output (5 beams / 5 sequences)\n",
    "# this is column 1 of table 3\n",
    "vt.load_and_run_t5('outputs/model_output.preds',\n",
    "                   # pre_truncate=5,        # should not be needed since we have only 5 outputs\n",
    "                   do_length_filter=True)\n",
    "\n",
    "# run on the anagram subset\n",
    "# this is column 2 of table 3\n",
    "vt.load_and_run_t5('outputs/model_output.preds',\n",
    "                   filter_fcn=vt.make_set_filter(labels, 'anag_direct'),\n",
    "                   # pre_truncate=5,\n",
    "                   do_length_filter=True)\n",
    "\n",
    "# we are looking at agg_top_match (which is after filter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}